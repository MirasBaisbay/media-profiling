# Media Profiler

A comprehensive media source analysis system that evaluates news outlets for **political bias**, **factual reliability**, and **overall credibility** using the [Media Bias/Fact Check (MBFC)](https://mediabiasfactcheck.com/methodology/) methodology.

## Table of Contents

- [Overview](#overview)
- [System Architecture](#system-architecture)
- [Methodology](#methodology)
  - [Bias Scoring](#bias-scoring)
  - [Factuality Scoring](#factuality-scoring)
  - [Credibility Calculation](#credibility-calculation)
- [Core Modules](#core-modules)
- [Analyzer Flow Diagrams](#analyzer-flow-diagrams)
- [Propaganda Detection](#propaganda-detection)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [References](#references)

---

## Overview

Media Profiler automates the evaluation of news sources by:

1. **Scraping** articles from target news websites
2. **Analyzing** content using LLM-based analyzers with structured output
3. **Detecting** propaganda techniques using fine-tuned DeBERTa models
4. **Researching** outlet history, ownership, and external analyses via web search
5. **Calculating** composite scores following MBFC methodology
6. **Generating** detailed credibility reports

### Key Features

- **MBFC-Compliant Scoring** - Implements scoring aligned with Media Bias/Fact Check methodology
- **LLM-Based Analysis** - Uses structured LLM output for type-safe, reliable analysis
- **Two-Stage Propaganda Detection** - DeBERTa-v3-Large for span identification + technique classification
- **Hybrid Analyzers** - Combines deterministic lookups (Tranco, WHOIS) with LLM fallbacks
- **Comprehensive Research** - Gathers history, ownership, and external analyses via web search
- **Multi-Site Fact Checking** - Searches IFCN-approved fact-checkers for failed fact checks

---

## System Architecture

### Complete Analysis Pipeline

```
                         MEDIA PROFILER - COMPLETE PIPELINE
================================================================================

                                   INPUT
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. SCRAPE NODE (scraper.py)                                                â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚     â”‚  MediaScraper                                                   â”‚     â”‚
â”‚     â”‚  â”œâ”€â”€ Fetch homepage + sitemap                                   â”‚     â”‚
â”‚     â”‚  â”œâ”€â”€ Collect up to 20 articles                                  â”‚     â”‚
â”‚     â”‚  â”œâ”€â”€ Separate News vs Opinion articles                          â”‚     â”‚
â”‚     â”‚  â”‚   â”œâ”€â”€ URL patterns (/opinion/, /editorial/)                  â”‚     â”‚
â”‚     â”‚  â”‚   â”œâ”€â”€ Schema.org metadata                                    â”‚     â”‚
â”‚     â”‚  â”‚   â””â”€â”€ Title patterns ("Opinion:", "Editorial:")              â”‚     â”‚
â”‚     â”‚  â””â”€â”€ Extract site metadata                                      â”‚     â”‚
â”‚     â”‚       â”œâ”€â”€ About page (ownership, funding)                       â”‚     â”‚
â”‚     â”‚       â”œâ”€â”€ Author information                                    â”‚     â”‚
â”‚     â”‚       â””â”€â”€ Location disclosure                                   â”‚     â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ANALYZE NODE (refactored_analyzers.py + research.py)                    â”‚
â”‚                                                                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚     â”‚    CONTENT ANALYZERS      â”‚   â”‚   METADATA ANALYZERS      â”‚           â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”‚
â”‚     â”‚ EditorialBiasAnalyzer     â”‚   â”‚ TrafficLongevityAnalyzer  â”‚           â”‚
â”‚     â”‚ PseudoscienceAnalyzer     â”‚   â”‚ MediaTypeAnalyzer         â”‚           â”‚
â”‚     â”‚ SourcingAnalyzer          â”‚   â”‚ OpinionAnalyzer           â”‚           â”‚
â”‚     â”‚ FactCheckSearcher         â”‚   â”‚                           â”‚           â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                             â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚  WEB RESEARCH (MediaResearcher)                                   â”‚   â”‚
â”‚     â”‚  â”œâ”€â”€ History research (founding, key events)                      â”‚   â”‚
â”‚     â”‚  â”œâ”€â”€ Ownership research (owner, funding, headquarters)            â”‚   â”‚
â”‚     â”‚  â””â”€â”€ External analysis (MBFC, NewsGuard, academic reviews)        â”‚   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. REPORT NODE (research.py)                                               â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚     â”‚  MediaProfiler                                                  â”‚     â”‚
â”‚     â”‚  â”œâ”€â”€ Calculate bias score and label                             â”‚     â”‚
â”‚     â”‚  â”œâ”€â”€ Calculate factuality score and label                       â”‚     â”‚
â”‚     â”‚  â”œâ”€â”€ Calculate credibility score and label                      â”‚     â”‚
â”‚     â”‚  â””â”€â”€ Generate comprehensive MBFC-style report                   â”‚     â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                                  OUTPUT
```

### Scoring Components

```
+-----------------------------------------------------------------------------+
|           BIAS SCORING (-10 to +10)    |    FACTUALITY SCORING (0-10)       |
|----------------------------------------|-------------------------------------|
|                                        |                                     |
|  EditorialBiasAnalyzer                 |  FactCheckSearcher          (40%)  |
|  LLM-based political bias detection    |  IFCN-approved fact-checker search |
|  -10 Left -> +10 Right                 |                                     |
|                                        |  SourcingAnalyzer           (30%)  |
|  Policy positions detected:            |  Link extraction + LLM quality     |
|  - Economic, Social, Environmental     |                                     |
|  - Healthcare, Immigration, etc.       |  PseudoscienceAnalyzer      (30%)  |
|  - Loaded language identification      |  Science misinformation detection  |
|                                        |                                     |
+-----------------------------------------------------------------------------+
|                                                                             |
|                           CREDIBILITY SCORE (0-10)                          |
|  = FactCheck (40%) + Sourcing (30%) + Pseudoscience (30%)                   |
|                                                                             |
+-----------------------------------------------------------------------------+
```

---

## Methodology

### Bias Scoring

Scale: **-10 (Extreme Left) to +10 (Extreme Right)**

The `EditorialBiasAnalyzer` uses LLM analysis to evaluate:

| Indicator | Description |
|-----------|-------------|
| **Policy Positions** | Economic, Social, Environmental, Healthcare, Immigration, Gun Rights |
| **Loaded Language** | Left-loaded terms ("regime", "far-right") vs Right-loaded ("woke", "radical left") |
| **Story Selection** | Topics chosen and framing patterns |

**Bias Labels:**
| Score Range | Label |
|-------------|-------|
| -10 to -7.0 | Left |
| -7.0 to -3.0 | Left-Center |
| -3.0 to +3.0 | Center |
| +3.0 to +7.0 | Right-Center |
| +7.0 to +10 | Right |

### Factuality Scoring

Scale: **0 (Best) to 10 (Worst)**

| Component | Weight | Description |
|-----------|--------|-------------|
| **Failed Fact Checks** | 40% | Count from IFCN-approved fact-checkers |
| **Sourcing Quality** | 30% | Link extraction + LLM quality assessment |
| **Pseudoscience** | 30% | Detection of science misinformation |

**Factuality Labels:**
| Score Range | Label |
|-------------|-------|
| 0.0 - 2.0 | Very High |
| 2.0 - 4.0 | High |
| 4.0 - 6.0 | Mixed |
| 6.0 - 8.0 | Low |
| 8.0 - 10.0 | Very Low |

### Credibility Calculation

```
Credibility = FactCheck (40%) + Sourcing (30%) + Pseudoscience (30%)
```

**Credibility Levels:**
| Score Range | Label |
|-------------|-------|
| 0.0 - 2.0 | Very High Credibility |
| 2.0 - 4.0 | High Credibility |
| 4.0 - 6.0 | Medium Credibility |
| 6.0 - 8.0 | Low Credibility |
| 8.0 - 10.0 | Very Low Credibility |

---

## Core Modules

### research.py - Orchestration & Research

Main orchestrator combining web research with comprehensive profiling.

**Components:**
- `MediaResearcher` - Gathers history, ownership, and external analysis via direct site scraping + web search
  - **About page scraping**: Directly fetches `/about`, `/about-us` pages from the outlet
  - **Outlet name resolution**: URL heuristics + LLM fallback for official names (e.g., `apnews` â†’ `The Associated Press`)
  - **Tiered research**: About page â†’ DuckDuckGo search â†’ Wikipedia â†’ domain-based fallback
  - **Social media blacklist**: Filters out Facebook, Twitter/X, Instagram, TikTok, Pinterest, LinkedIn, Reddit, YouTube from search results
- `MediaProfiler` - Orchestrates all analyzers to produce MBFC-style reports

### refactored_analyzers.py - LLM-Based Analyzers

All analyzers use LangChain's structured output for type-safe LLM responses:

**Content Analyzers:**
- `OpinionAnalyzer` - Article type classification (News/Opinion/Satire/PR)
- `EditorialBiasAnalyzer` - LLM-based political bias detection
- `PseudoscienceAnalyzer` - Science misinformation detection
- `SourcingAnalyzer` - Link extraction + LLM quality assessment
- `FactCheckSearcher` - Multi-site fact-checker search + LLM parsing

**Metadata Analyzers:**
- `TrafficLongevityAnalyzer` - Hybrid Tranco + WHOIS + LLM
- `MediaTypeAnalyzer` - Hybrid lookup + LLM classification

### scraper.py - Web Scraping Engine

Brute-force article collection with:
- Browser-like headers to avoid blocking
- Rate limiting (0.5-1.5s delays)
- Threaded parallel scraping (5 workers)
- Opinion article detection (URL, title, meta tags, schema.org)
- Metadata extraction (about page, ownership, funding, authors)

### local_detector.py - DeBERTa Inference Pipeline

Two-stage propaganda detection using fine-tuned DeBERTa models:
- Stage 1: Span Identification (Token Classification)
- Stage 2: Technique Classification (Sequence Classification)

### parser.py - MBFC Website Parser

Specialized parser for scraping Media Bias/Fact Check website to collect source URLs.

---

## Analyzer Flow Diagrams

### TrafficLongevityAnalyzer

Hybrid deterministic + LLM approach for traffic and domain age analysis.

```
analyze(domain)
    â”‚
    â”œâ”€â–º 1. WHOIS Lookup (always runs)
    â”‚       â””â”€â–º Extract creation_date â†’ Calculate age_years
    â”‚
    â”œâ”€â–º 2. Tranco Lookup (O(1) dict lookup)
    â”‚       â”‚   Source: https://tranco-list.eu/
    â”‚       â”‚   - Top 1M domains ranked by popularity
    â”‚       â”‚   - Auto-downloads if missing
    â”‚       â”‚
    â”‚       â”œâ”€â–º Found?
    â”‚       â”‚       â”œâ”€â–º rank < 10,000    â†’ HIGH traffic
    â”‚       â”‚       â”œâ”€â–º rank < 100,000   â†’ MEDIUM traffic
    â”‚       â”‚       â”œâ”€â–º rank < 1,000,000 â†’ LOW traffic
    â”‚       â”‚       â””â”€â–º Return with confidence=1.0, source=TRANCO
    â”‚       â”‚
    â”‚       â””â”€â–º Not found? â†’ Continue to step 3
    â”‚
    â””â”€â–º 3. LLM Fallback
            â”œâ”€â–º Search: "{domain} traffic stats similarweb hypestat semrush"
            â”œâ”€â–º Combine top 5 result snippets
            â””â”€â–º Parse with structured LLM output â†’ TrafficEstimate
                    â”œâ”€â–º traffic_tier: HIGH/MEDIUM/LOW/MINIMAL/UNKNOWN
                    â”œâ”€â–º monthly_visits_estimate (if found)
                    â”œâ”€â–º confidence: 0.0-1.0
                    â””â”€â–º reasoning

OUTPUT: TrafficData
    â”œâ”€â”€ domain, creation_date, age_years
    â”œâ”€â”€ traffic_tier, traffic_confidence
    â”œâ”€â”€ traffic_source: TRANCO | LLM | FALLBACK
    â”œâ”€â”€ tranco_rank (if available)
    â””â”€â”€ whois_success, whois_error
```

### MediaTypeAnalyzer

Hybrid lookup table + LLM approach for media type classification.

```
analyze(url_or_domain)
    â”‚
    â”œâ”€â–º 1. Known Types Lookup (O(1) dict)
    â”‚       â”‚   Source: known_media_types.csv
    â”‚       â”‚   - Pre-classified major outlets
    â”‚       â”‚   - Maps domain â†’ MediaType enum
    â”‚       â”‚
    â”‚       â”œâ”€â–º Found?
    â”‚       â”‚       â””â”€â–º Return with confidence=1.0, source=LOOKUP
    â”‚       â”‚
    â”‚       â””â”€â–º Not found? â†’ Continue to step 2
    â”‚
    â””â”€â–º 2. LLM Classification
            â”œâ”€â–º Search: '"{domain}" type of media outlet newspaper television website magazine'
            â”œâ”€â–º Fallback: "{site_name} wikipedia media company"
            â””â”€â–º Parse with structured LLM output â†’ MediaTypeLLMOutput
                    â”œâ”€â–º media_type: TV/NEWSPAPER/WEBSITE/MAGAZINE/RADIO/NEWS_AGENCY/BLOG/PODCAST/STREAMING/UNKNOWN
                    â”œâ”€â–º confidence: 0.0-1.0
                    â””â”€â–º reasoning

OUTPUT: MediaTypeClassification
    â”œâ”€â”€ media_type: MediaType enum
    â”œâ”€â”€ confidence: 0.0-1.0
    â”œâ”€â”€ source: LOOKUP | LLM | FALLBACK
    â””â”€â”€ reasoning
```

### FactCheckSearcher (40% of Factuality Score)

Multi-site search + LLM parsing for fact-check findings.

```
analyze(url_or_domain, outlet_name?)
    â”‚
    â”œâ”€â–º 1. Extract Domain & Outlet Name
    â”‚       â”œâ”€â–º "nytimes.com" â†’ "New York Times"
    â”‚       â””â”€â–º Uses known_names dict or generates from domain
    â”‚
    â”œâ”€â–º 2. Search 5 Fact-Checker Sites
    â”‚       â”‚   Sites:
    â”‚       â”‚   â”œâ”€â”€ mediabiasfactcheck.com
    â”‚       â”‚   â”œâ”€â”€ politifact.com
    â”‚       â”‚   â”œâ”€â”€ snopes.com
    â”‚       â”‚   â”œâ”€â”€ factcheck.org
    â”‚       â”‚   â””â”€â”€ fullfact.org
    â”‚       â”‚
    â”‚       â”‚   Query format:
    â”‚       â”‚   site:{site} "{domain}" OR "{outlet_name}"
    â”‚       â”‚
    â”‚       â””â”€â–º Collect up to 3 results per site â†’ Combine snippets
    â”‚
    â”œâ”€â–º 3. LLM Parsing
    â”‚       â””â”€â–º Parse snippets â†’ FactCheckLLMOutput
    â”‚               â”œâ”€â–º findings: List[FactCheckFinding]
    â”‚               â”‚       â”œâ”€â”€ source_site (PolitiFact, Snopes, etc.)
    â”‚               â”‚       â”œâ”€â”€ claim_summary
    â”‚               â”‚       â”œâ”€â”€ verdict: TRUE/MOSTLY_TRUE/HALF_TRUE/MIXED/
    â”‚               â”‚       â”‚            MOSTLY_FALSE/FALSE/PANTS_ON_FIRE/
    â”‚               â”‚       â”‚            MISLEADING/UNPROVEN/NOT_RATED
    â”‚               â”‚       â””â”€â”€ url (if available)
    â”‚               â”œâ”€â–º failed_count (FALSE, MOSTLY_FALSE, PANTS_ON_FIRE, MISLEADING)
    â”‚               â”œâ”€â–º total_count
    â”‚               â””â”€â–º confidence, reasoning
    â”‚
    â””â”€â–º 4. Score Calculation
            â”œâ”€â–º 0 failed checks    â†’ 0.0 (excellent)
            â”œâ”€â–º 1-2 failed checks  â†’ 2.0-4.0
            â”œâ”€â–º 3-5 failed checks  â†’ 5.0-7.0
            â”œâ”€â–º 6+ failed checks   â†’ 8.0-10.0 (very poor)
            â””â”€â–º No data found      â†’ 5.0 (neutral)

OUTPUT: FactCheckAnalysisResult
    â”œâ”€â”€ domain, outlet_name
    â”œâ”€â”€ failed_checks_count, total_checks_count
    â”œâ”€â”€ score: 0.0-10.0
    â”œâ”€â”€ source: SEARCH | FALLBACK
    â”œâ”€â”€ findings: List[FactCheckFinding]
    â””â”€â”€ confidence, reasoning
```

### SourcingAnalyzer (30% of Factuality Score)

Link extraction + LLM quality assessment for source evaluation.

```
analyze(articles: List[{text}])
    â”‚
    â”œâ”€â–º 1. Extract Links from All Articles
    â”‚       â””â”€â–º Regex: https?://[^\s<>"')\]]+
    â”‚
    â”œâ”€â–º 2. Extract Unique Domains
    â”‚       â”‚   Filter out social media:
    â”‚       â”‚   â”œâ”€â”€ twitter.com, x.com
    â”‚       â”‚   â”œâ”€â”€ facebook.com, instagram.com
    â”‚       â”‚   â”œâ”€â”€ youtube.com, tiktok.com
    â”‚       â”‚   â”œâ”€â”€ linkedin.com, reddit.com
    â”‚       â”‚   â””â”€â”€ t.co (Twitter short links)
    â”‚       â”‚
    â”‚       â””â”€â–º No domains found? â†’ Return score=5.0 (neutral)
    â”‚
    â””â”€â–º 3. LLM Quality Assessment
            â””â”€â–º Assess each domain â†’ SourcingLLMOutput
                    â”œâ”€â–º sources_assessed: List[SourceAssessment]
                    â”‚       â”œâ”€â”€ domain
                    â”‚       â”œâ”€â”€ quality: PRIMARY/WIRE_SERVICE/MAJOR_OUTLET/
                    â”‚       â”‚            CREDIBLE/UNKNOWN/QUESTIONABLE
                    â”‚       â””â”€â”€ reasoning
                    â”œâ”€â–º overall_quality_score: 0.0-10.0
                    â”œâ”€â–º has_primary_sources: bool
                    â”œâ”€â–º has_wire_services: bool
                    â””â”€â–º overall_assessment

Quality Tiers:
    PRIMARY       â†’ .gov, .edu, official sources, research papers
    WIRE_SERVICE  â†’ Reuters, AP, AFP, UPI
    MAJOR_OUTLET  â†’ NYT, BBC, WSJ, WaPo, Guardian, CNN
    CREDIBLE      â†’ Regional papers, trade publications
    UNKNOWN       â†’ Unfamiliar domains
    QUESTIONABLE  â†’ Known unreliable sources

OUTPUT: SourcingAnalysisResult
    â”œâ”€â”€ score: 0.0-10.0 (0=excellent, 10=poor)
    â”œâ”€â”€ avg_sources_per_article
    â”œâ”€â”€ total_sources_found, unique_domains
    â”œâ”€â”€ has_hyperlinks, has_primary_sources, has_wire_services
    â”œâ”€â”€ source_assessments: List[SourceAssessment]
    â””â”€â”€ confidence, reasoning
```

### EditorialBiasAnalyzer

LLM-based comprehensive political bias detection.

```
analyze(articles: List[{title, text}], url_or_domain?, outlet_name?)
    â”‚
    â”œâ”€â–º 1. Format Articles for Analysis
    â”‚       â””â”€â–º Combine title + first 2000 chars of each article
    â”‚
    â””â”€â–º 2. LLM Analysis with MBFC Methodology
            â”‚
            â”‚   System Prompt encodes:
            â”‚   â”œâ”€â”€ Bias Scale: -10 (far left) to +10 (far right)
            â”‚   â”œâ”€â”€ Policy Domain Indicators:
            â”‚   â”‚       â”œâ”€â”€ Economic Policy (taxes, regulation, unions)
            â”‚   â”‚       â”œâ”€â”€ Social Issues (abortion, LGBTQ+, guns)
            â”‚   â”‚       â”œâ”€â”€ Environmental Policy (climate, regulations)
            â”‚   â”‚       â”œâ”€â”€ Healthcare (universal vs private)
            â”‚   â”‚       â”œâ”€â”€ Immigration (pathways vs enforcement)
            â”‚   â”‚       â””â”€â”€ Gun Rights (control vs 2A)
            â”‚   â”œâ”€â”€ Loaded Language Detection:
            â”‚   â”‚       â”œâ”€â”€ LEFT: "regime", "far-right", "fascist", "climate denier"
            â”‚   â”‚       â””â”€â”€ RIGHT: "radical left", "woke", "cancel culture", "fake news"
            â”‚   â””â”€â”€ Story Selection Bias patterns
            â”‚
            â””â”€â–º Parse â†’ EditorialBiasLLMOutput
                    â”œâ”€â–º overall_bias: EXTREME_LEFT/LEFT/LEFT_CENTER/CENTER/
                    â”‚                 RIGHT_CENTER/RIGHT/EXTREME_RIGHT
                    â”œâ”€â–º bias_score: -10.0 to +10.0
                    â”œâ”€â–º policy_positions: List[PolicyPosition]
                    â”‚       â”œâ”€â”€ domain: ECONOMIC/SOCIAL/ENVIRONMENTAL/HEALTHCARE/
                    â”‚       â”‚           IMMIGRATION/FOREIGN_POLICY/GUN_RIGHTS/EDUCATION
                    â”‚       â”œâ”€â”€ leaning: BiasDirection
                    â”‚       â”œâ”€â”€ indicators: List[str]
                    â”‚       â””â”€â”€ confidence
                    â”œâ”€â–º uses_loaded_language: bool
                    â”œâ”€â–º loaded_language_examples: List[str]
                    â”œâ”€â–º story_selection_bias: str (optional)
                    â””â”€â–º confidence, reasoning

Score to Label Mapping:
    score <= -7  â†’ "Left"
    -7 < score <= -3 â†’ "Left-Center"
    -3 < score <= 3  â†’ "Center"
    3 < score <= 7   â†’ "Right-Center"
    score > 7    â†’ "Right"

OUTPUT: EditorialBiasResult
    â”œâ”€â”€ domain, outlet_name
    â”œâ”€â”€ overall_bias: BiasDirection
    â”œâ”€â”€ bias_score: -10.0 to +10.0
    â”œâ”€â”€ mbfc_label: "Left"/"Left-Center"/"Center"/"Right-Center"/"Right"
    â”œâ”€â”€ policy_positions, loaded_language_examples
    â”œâ”€â”€ articles_analyzed
    â””â”€â”€ confidence, reasoning
```

### PseudoscienceAnalyzer (30% of Factuality Score)

LLM-based detection of pseudoscience and conspiracy content.

```
analyze(articles: List[{title, text}], url_or_domain?, outlet_name?)
    â”‚
    â”œâ”€â–º 1. Format Articles for Analysis
    â”‚       â””â”€â–º Combine title + first 2000 chars of each article
    â”‚
    â””â”€â–º 2. LLM Analysis with Scientific Consensus
            â”‚
            â”‚   System Prompt includes:
            â”‚   â”œâ”€â”€ Pseudoscience Definition
            â”‚   â”‚       "Claims presented as scientific but incompatible
            â”‚   â”‚        with scientific method - unproven, untestable,
            â”‚   â”‚        or contradicting scientific consensus"
            â”‚   â”‚
            â”‚   â”œâ”€â”€ Categories to Detect:
            â”‚   â”‚   HEALTH:
            â”‚   â”‚   â”œâ”€â”€ Anti-Vaccination (vaccines cause autism, etc.)
            â”‚   â”‚   â”œâ”€â”€ Alternative Medicine (homeopathy, crystal healing)
            â”‚   â”‚   â”œâ”€â”€ Alternative Cancer Treatments
            â”‚   â”‚   â”œâ”€â”€ COVID-19 Misinformation
            â”‚   â”‚   â””â”€â”€ Detoxification Claims
            â”‚   â”‚
            â”‚   â”‚   CLIMATE/ENVIRONMENTAL:
            â”‚   â”‚   â”œâ”€â”€ Climate Change Denialism
            â”‚   â”‚   â”œâ”€â”€ 5G Health Conspiracy
            â”‚   â”‚   â”œâ”€â”€ Chemtrails
            â”‚   â”‚   â””â”€â”€ GMO Danger Claims
            â”‚   â”‚
            â”‚   â”‚   PARANORMAL:
            â”‚   â”‚   â”œâ”€â”€ Astrology, Psychic Claims
            â”‚   â”‚   â””â”€â”€ Faith Healing
            â”‚   â”‚
            â”‚   â”‚   CONSPIRACY:
            â”‚   â”‚   â”œâ”€â”€ Flat Earth, Moon Landing Hoax
            â”‚   â”‚   â””â”€â”€ QAnon
            â”‚   â”‚
            â”‚   â””â”€â”€ Severity Assessment:
            â”‚           PROMOTES â†’ Actively promotes as fact
            â”‚           PRESENTS_UNCRITICALLY â†’ Reports without context
            â”‚           MIXED â†’ Inconsistent treatment
            â”‚           NONE_DETECTED â†’ Respects scientific consensus
            â”‚
            â””â”€â–º Parse â†’ PseudoscienceLLMOutput
                    â”œâ”€â–º indicators: List[PseudoscienceIndicator]
                    â”‚       â”œâ”€â”€ category: PseudoscienceCategory
                    â”‚       â”œâ”€â”€ severity: PseudoscienceSeverity
                    â”‚       â”œâ”€â”€ evidence: str
                    â”‚       â””â”€â”€ scientific_consensus: str
                    â”œâ”€â–º promotes_pseudoscience: bool
                    â”œâ”€â–º overall_severity: PseudoscienceSeverity
                    â”œâ”€â–º science_reporting_quality: 0.0-10.0
                    â”œâ”€â–º respects_scientific_consensus: bool
                    â””â”€â–º confidence, reasoning

OUTPUT: PseudoscienceAnalysisResult
    â”œâ”€â”€ domain, outlet_name
    â”œâ”€â”€ score: 0.0-10.0 (0=pro-science, 10=promotes pseudoscience)
    â”œâ”€â”€ promotes_pseudoscience: bool
    â”œâ”€â”€ overall_severity: PROMOTES/PRESENTS_UNCRITICALLY/MIXED/NONE_DETECTED
    â”œâ”€â”€ categories_found: List[PseudoscienceCategory]
    â”œâ”€â”€ indicators: List[PseudoscienceIndicator]
    â”œâ”€â”€ respects_scientific_consensus: bool
    â”œâ”€â”€ articles_analyzed
    â””â”€â”€ confidence, reasoning
```

### MediaResearcher - Outlet Name Resolution

Resolves the official outlet name from URL with LLM fallback.

```
resolve_outlet_name(url, domain)
    â”‚
    â”œâ”€â–º 1. URL Heuristic
    â”‚       â”œâ”€â–º Extract domain base: "bbc.com" â†’ "bbc"
    â”‚       â”œâ”€â–º Short names (â‰¤4 chars) â†’ UPPERCASE: "bbc" â†’ "BBC"
    â”‚       â””â”€â–º Longer names â†’ Title Case: "foxnews" â†’ "Foxnews"
    â”‚
    â”œâ”€â–º 2. About Page Scrape (LLM fallback)
    â”‚       â”œâ”€â–º Try: /about, /about-us, /about/, /about-us/,
    â”‚       â”‚        /corporate/about, /company/about
    â”‚       â”œâ”€â–º Extract page text (up to 5000 chars)
    â”‚       â””â”€â–º LLM extracts official name from about page
    â”‚           â”œâ”€â–º "apnews" â†’ "The Associated Press"
    â”‚           â”œâ”€â–º "foxnews" â†’ "Fox News"
    â”‚           â””â”€â–º "nytimes" â†’ "The New York Times"
    â”‚
    â””â”€â–º OUTPUT: Official outlet name (string)
```

### MediaResearcher - History Research

Tiered approach to gathering outlet history information.

```
research_history(outlet_name, domain)
    â”‚
    â”œâ”€â–º Tier 1: DIRECT ABOUT PAGE SCRAPE
    â”‚       â”œâ”€â–º Fetch /about, /about-us from the site itself
    â”‚       â”œâ”€â–º Most authoritative source for history/ownership
    â”‚       â””â”€â–º Returns page text if found (>200 chars)
    â”‚
    â”œâ”€â–º Tier 2: DUCKDUCKGO SEARCH
    â”‚       â”œâ”€â–º Query: "{outlet_name}" about us founded history
    â”‚       â””â”€â–º Filters out social media via SEARCH_BLACKLIST
    â”‚
    â”œâ”€â–º Tier 3: WIKIPEDIA FALLBACK
    â”‚       â””â”€â–º Query: "{outlet_name}" wikipedia founded history
    â”‚
    â”œâ”€â–º Tier 4: DOMAIN-BASED SEARCH
    â”‚       â””â”€â–º Query: {domain} history founded owner media
    â”‚
    â””â”€â–º LLM Extraction â†’ HistoryLLMOutput
            â”œâ”€â–º official_name (used to update outlet name)
            â”œâ”€â–º founding_year, founder
            â”œâ”€â–º original_name (if different)
            â”œâ”€â–º key_events: List[str]
            â”œâ”€â–º summary: 2-3 sentence history
            â””â”€â–º confidence

SEARCH BLACKLIST (filtered from all results):
    facebook.com, twitter.com, x.com, instagram.com,
    tiktok.com, pinterest.com, linkedin.com, reddit.com, youtube.com
```

### MediaResearcher - Ownership & External Analysis

```
research_ownership(outlet_name, domain)
    â”‚
    â”œâ”€â–º Search: "{outlet_name}" ownership owner parent company funded by
    â”œâ”€â–º Fallback: {domain} ownership owner parent company
    â””â”€â–º LLM Extraction â†’ OwnershipLLMOutput
            â”œâ”€â–º owner, parent_company
            â”œâ”€â–º funding_model (advertising/subscription/public/nonprofit/mixed)
            â”œâ”€â–º headquarters (city, country)
            â””â”€â–º notes, confidence

research_external_analysis(outlet_name, domain)
    â”‚
    â”œâ”€â–º Search: "{outlet_name}" media bias analysis criticism review
    â”œâ”€â–º Targets: MBFC, Ad Fontes, NewsGuard, CJR, Nieman Lab
    â””â”€â–º LLM Extraction â†’ ExternalAnalysisLLMOutput
            â””â”€â–º analyses: List[ExternalAnalysisItem]
                    â”œâ”€â”€ source_name, source_url
                    â”œâ”€â”€ summary
                    â””â”€â”€ sentiment: positive/negative/neutral/mixed
```

---

## Propaganda Detection

### Two-Stage DeBERTa Pipeline

```
INPUT: "The radical left wants to destroy our great nation..."

+------------------------------------------------------------------+
|  STAGE 1: SPAN IDENTIFICATION (SI)                                |
|  Model: DeBERTa-v3-Large (Token Classification, BIO tagging)      |
|  Task: Find WHERE propaganda exists                               |
|                                                                   |
|  Input:  ["The", "radical", "left", "wants", "to", ...]          |
|  Output: [ O,    B-PROP,   I-PROP,  O,      O,  ...]              |
|                  ^^^^^^^^^^^^^^                                   |
|                  Detected Span                                    |
+------------------------------------------------------------------+
                              |
                              v
+------------------------------------------------------------------+
|  STAGE 2: TECHNIQUE CLASSIFICATION (TC)                           |
|  Model: DeBERTa-v3-Large (Sequence Classification, 14 classes)    |
|  Task: Identify WHICH technique is used                           |
|                                                                   |
|  Input:  "[Context] [SEP] radical left"                           |
|  Output: "Name_Calling,Labeling" (confidence: 0.87)               |
+------------------------------------------------------------------+
```

### Propaganda Techniques (14 Classes)

| # | Technique | Description |
|---|-----------|-------------|
| 1 | Appeal_to_Authority | Citing authority figures to support claims |
| 2 | Appeal_to_fear-prejudice | Using fear or prejudice to influence |
| 3 | Bandwagon,Reductio_ad_Hitlerum | "Everyone does it" or Nazi comparisons |
| 4 | Black-and-White_Fallacy | Presenting only two choices |
| 5 | Causal_Oversimplification | Oversimplifying cause-effect |
| 6 | Doubt | Questioning credibility without evidence |
| 7 | Exaggeration,Minimisation | Overstating or understating facts |
| 8 | Flag-Waving | Appealing to patriotism/nationalism |
| 9 | Loaded_Language | Using emotionally charged words |
| 10 | Name_Calling,Labeling | Using derogatory labels |
| 11 | Repetition | Repeating messages for emphasis |
| 12 | Slogans | Using catchy phrases |
| 13 | Thought-terminating_Cliches | Phrases discouraging critical thinking |
| 14 | Whataboutism,Straw_Men,Red_Herring | Deflection tactics |

### Training Configuration

```python
Model: microsoft/deberta-v3-large (304M parameters)

SI Model (Span Identification):
  max_length = 512
  learning_rate = 1e-5
  batch_size = 4 (effective 32 with accumulation)
  epochs = 15

TC Model (Technique Classification):
  max_length = 384
  learning_rate = 1.5e-5
  batch_size = 8 (effective 64 with accumulation)
  epochs = 10

Features:
  - Focal loss for class imbalance
  - Early stopping (patience=4)
  - SemEval 2020 Task 11 dataset
```

---

## Installation

### Requirements

- Python 3.8+
- PyTorch with CUDA (recommended for training)
- 16GB+ RAM for inference
- 24GB+ GPU VRAM for training

### Setup

```bash
# Clone repository
git clone https://github.com/MirasBaisbay/media-profiling.git
cd media-profiling

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install torch transformers datasets beautifulsoup4 \
            requests scikit-learn duckduckgo-search openai langchain-openai pydantic

# Set API key (for LLM-based analyzers)
export OPENAI_API_KEY="your-api-key"
```

### Train Models (Optional)

```bash
# Ensure datasets/ folder contains SemEval 2020 Task 11 data
python train_pipeline.py
```

---

## Usage

### Web Interface (Streamlit)

```bash
# Run locally
streamlit run app.py

# Opens at http://localhost:8501
```

### Deploy to HuggingFace Spaces

Follow these steps to deploy Media Profiler as a public (or private) web app on HuggingFace Spaces.

#### Step 1: Create a HuggingFace Account

If you don't have one, sign up at [huggingface.co/join](https://huggingface.co/join).

#### Step 2: Create a New Space

1. Go to [huggingface.co/new-space](https://huggingface.co/new-space)
2. Fill in the form:
   - **Owner**: Your username or organization
   - **Space name**: `media-profiler` (or any name you prefer)
   - **License**: MIT (or your preferred license)
   - **SDK**: Select **Streamlit**
   - **Visibility**: Public or Private
3. Click **Create Space**

#### Step 3: Add Your OpenAI API Key as a Secret

The app needs an OpenAI API key for LLM-based analysis. **Never commit your key to the repo.**

1. Go to your Space's page: `https://huggingface.co/spaces/<your-username>/media-profiler`
2. Click **Settings** (gear icon in the top-right)
3. Scroll down to **Repository secrets**
4. Click **New secret**:
   - **Name**: `OPENAI_API_KEY`
   - **Value**: Your OpenAI API key (e.g., `sk-...`)
5. Click **Save**

The app reads this automatically via `os.environ["OPENAI_API_KEY"]`.

#### Step 4: Clone the Space and Push Your Code

```bash
# Option A: Clone the empty Space repo and copy files into it
git clone https://huggingface.co/spaces/<your-username>/media-profiler
cd media-profiler

# Copy all project files into this directory
# (app.py, requirements.txt, schemas.py, research.py, scraper.py, etc.)

# Option B: Add the Space as a remote to your existing repo
cd /path/to/your/media-profiling
git remote add space https://huggingface.co/spaces/<your-username>/media-profiler
```

#### Step 5: Verify Required Files

Make sure these files exist in the root of the repo:

| File | Purpose |
|------|---------|
| `app.py` | Streamlit entry point (HuggingFace auto-detects this) |
| `requirements.txt` | Python dependencies installed automatically |
| `schemas.py` | Pydantic data models |
| `research.py` | Research orchestrator |
| `refactored_analyzers.py` | LLM-based analyzers |
| `scraper.py` | Web scraper |
| `report_generator.py` | Report prose generation |
| `storage.py` | Report caching |
| `config.py` | Configuration constants |
| `known_media_types.csv` | Lookup table for media type classification |

> **Note**: You do **not** need `main_pipeline.py`, `train_pipeline.py`, `local_detector.py`, `parser.py`, or the `datasets/` and `propaganda_models/` directories for the web interface. These are optional.

#### Step 6: Push to HuggingFace

```bash
# If using Option A (cloned Space repo):
git add .
git commit -m "Deploy Media Profiler to HuggingFace Spaces"
git push origin main

# If using Option B (added as remote):
git push space main
```

HuggingFace will automatically:
1. Detect the Streamlit SDK from `requirements.txt`
2. Install all dependencies
3. Run `streamlit run app.py`
4. Provide a public URL like `https://<your-username>-media-profiler.hf.space`

#### Step 7: Verify the Deployment

1. Go to `https://huggingface.co/spaces/<your-username>/media-profiler`
2. Wait for the build to complete (first build takes 2-5 minutes)
3. You should see the Media Profiler interface with:
   - A sidebar with URL input and previous reports
   - Landing page explaining the methodology
4. Enter a URL (e.g., `https://www.bbc.com`) and click **Analyze**

#### Troubleshooting

| Problem | Solution |
|---------|----------|
| **Build fails** | Check the **Logs** tab in your Space. Usually a missing dependency in `requirements.txt` |
| **"OPENAI_API_KEY not set"** | Add the secret in Settings > Repository secrets (Step 3) |
| **App crashes on analysis** | Check the Logs tab for Python tracebacks. Common issue: the LLM model name might need updating |
| **Slow first analysis** | Normal â€” scraping + 7 LLM calls + research takes 2-5 minutes. Subsequent analyses use cache |
| **"No articles found"** | Some sites block HuggingFace's IP range. Try a different news site |
| **Space sleeps after inactivity** | Free Spaces sleep after ~48h. Upgrade to a persistent Space or just re-visit to wake it |

#### Optional: Custom Space Configuration

Create a `README.md` at the root of your Space repo with HuggingFace metadata (this replaces the project README for the Space):

```yaml
---
title: Media Profiler
emoji: ðŸ“°
colorFrom: blue
colorTo: indigo
sdk: streamlit
sdk_version: "1.30.0"
app_file: app.py
pinned: false
---
```

This controls the Space's title, emoji, and SDK version on the HuggingFace directory.

### Command Line

```bash
# Run the CLI profiler
python main_pipeline.py https://www.bbc.com

# Force re-analysis (ignore cache)
python main_pipeline.py https://www.bbc.com --refresh
```

### Programmatic

```python
from research import MediaProfiler

# Initialize profiler
profiler = MediaProfiler()

# Sample articles (in practice, use scraper.py to collect these)
articles = [
    {
        "title": "Climate Change Policy Faces Opposition",
        "text": "The administration's new climate policy has drawn criticism..."
    },
    {
        "title": "Healthcare Reform Debate Intensifies",
        "text": "As healthcare costs continue to rise, lawmakers are divided..."
    },
]

# Profile an outlet
report = profiler.profile("https://www.bbc.com", articles)

# Generate text report
report_text = profiler.generate_report_text(report)
print(report_text)
```

### Sample Output

```
======================================================================
MEDIA BIAS/FACT CHECK REPORT: BBC
======================================================================
URL: https://www.bbc.com
Analysis Date: 2025-01-15

QUICK SUMMARY
----------------------------------------
  Bias Rating:        Left-Center
  Factuality Rating:  High
  Credibility:        High Credibility
  Media Type:         TV
  Traffic:            HIGH
  Domain Age:         28.5 years

HISTORY
----------------------------------------
  Founded: 1922
  Founder(s): John Reith
  Key Events:
    - First TV broadcasts 1936
    - Charter renewal 2017

  The BBC was founded in 1922 by John Reith...

FUNDED BY / OWNERSHIP
----------------------------------------
  Owner: British Public
  Funding: License Fee (public funding)
  Headquarters: London, United Kingdom

BIAS ANALYSIS
----------------------------------------
  Overall Bias: Left-Center (score: -2.5)
  Uses Loaded Language: No

FACTUALITY ANALYSIS
----------------------------------------
  Factuality Rating: High (score: 1.8/10)

  Fact Check Search Results:
    Total Fact Checks Found: 3
    Failed Fact Checks: 0

  Sourcing Quality:
    Score: 2.0/10
    Has Primary Sources: Yes
    Has Wire Services: Yes

PSEUDOSCIENCE CHECK
----------------------------------------
  Promotes Pseudoscience: No
  Respects Scientific Consensus: Yes

======================================================================
Articles Analyzed: 2
Generated by Media Profiling System
======================================================================
```

---

## Project Structure

```
media-profiling/
â”‚
â”œâ”€â”€ config.py                    # Configuration constants and scoring scales
â”‚   â”œâ”€â”€ Propaganda techniques (14 classes)
â”‚   â””â”€â”€ Model and training configurations
â”‚
â”œâ”€â”€ schemas.py                   # Pydantic v2 schemas for structured LLM outputs
â”‚   â”œâ”€â”€ Article Classification (ArticleType, ArticleClassification)
â”‚   â”œâ”€â”€ Media Type (MediaType, MediaTypeClassification)
â”‚   â”œâ”€â”€ Traffic/Longevity (TrafficTier, TrafficData)
â”‚   â”œâ”€â”€ Fact Check (FactCheckVerdict, FactCheckFinding, FactCheckAnalysisResult)
â”‚   â”œâ”€â”€ Sourcing (SourceQuality, SourceAssessment, SourcingAnalysisResult)
â”‚   â”œâ”€â”€ Editorial Bias (BiasDirection, PolicyPosition, EditorialBiasResult)
â”‚   â””â”€â”€ Pseudoscience (PseudoscienceCategory, PseudoscienceIndicator, PseudoscienceAnalysisResult)
â”‚
â”œâ”€â”€ refactored_analyzers.py      # LLM-based analyzers with structured output
â”‚   â”œâ”€â”€ OpinionAnalyzer (article type classification)
â”‚   â”œâ”€â”€ TrafficLongevityAnalyzer (hybrid Tranco + WHOIS + LLM)
â”‚   â”œâ”€â”€ MediaTypeAnalyzer (hybrid lookup + LLM)
â”‚   â”œâ”€â”€ FactCheckSearcher (multi-site search + LLM parsing)
â”‚   â”œâ”€â”€ SourcingAnalyzer (link extraction + LLM quality assessment)
â”‚   â”œâ”€â”€ EditorialBiasAnalyzer (LLM-based political bias)
â”‚   â””â”€â”€ PseudoscienceAnalyzer (LLM-based pseudoscience detection)
â”‚
â”œâ”€â”€ research.py                  # Web research and profiling orchestrator
â”‚   â”œâ”€â”€ MediaResearcher (about page scraping, history, ownership, external analysis)
â”‚   â”‚   â”œâ”€â”€ resolve_outlet_name() (URL heuristics + LLM about page fallback)
â”‚   â”‚   â”œâ”€â”€ _scrape_about_page() (direct /about page fetch)
â”‚   â”‚   â”œâ”€â”€ research_history() (tiered: about page â†’ search â†’ Wikipedia)
â”‚   â”‚   â”œâ”€â”€ research_ownership() (search + domain fallback)
â”‚   â”‚   â””â”€â”€ research_external_analysis() (media watchdog search)
â”‚   â”œâ”€â”€ MediaProfiler (comprehensive analysis orchestrator)
â”‚   â””â”€â”€ Convenience functions (research_outlet, profile_outlet)
â”‚
â”œâ”€â”€ app.py                       # Streamlit web interface (HuggingFace Spaces ready)
â”‚
â”œâ”€â”€ main_pipeline.py             # CLI entry point: scrape â†’ profile â†’ generate â†’ save
â”‚
â”œâ”€â”€ report_generator.py          # LLM-based MBFC prose report generation
â”‚   â””â”€â”€ ReportGenerator (GPT-4o synthesis with structured prompting)
â”‚
â”œâ”€â”€ storage.py                   # Persistence layer (30-day cache)
â”‚   â””â”€â”€ StorageManager (JSON + Markdown report caching)
â”‚
â”œâ”€â”€ requirements.txt             # Python dependencies for deployment
â”‚
â”œâ”€â”€ scraper.py                   # Web scraping for articles and metadata
â”‚   â”œâ”€â”€ MediaScraper
â”‚   â”œâ”€â”€ Article dataclass
â”‚   â””â”€â”€ SiteMetadata dataclass
â”‚
â”œâ”€â”€ local_detector.py            # DeBERTa inference pipeline
â”‚   â””â”€â”€ LocalPropagandaDetector
â”‚
â”œâ”€â”€ train_pipeline.py            # DeBERTa fine-tuning pipeline
â”‚
â”œâ”€â”€ parser.py                    # MBFC website parser
â”‚
â”œâ”€â”€ known_media_types.csv        # Pre-classified media outlet types
â”‚
â”œâ”€â”€ tranco_top1m.csv             # Tranco top 1M domains (auto-downloaded)
â”‚
â”œâ”€â”€ 2025.csv                     # Freedom Index dataset (181 countries)
â”‚
â”œâ”€â”€ verify_*.py                  # Verification scripts for analyzers
â”‚   â”œâ”€â”€ verify_factcheck.py
â”‚   â”œâ”€â”€ verify_sourcing.py
â”‚   â”œâ”€â”€ verify_editorial_bias.py
â”‚   â”œâ”€â”€ verify_pseudoscience.py
â”‚   â”œâ”€â”€ verify_traffic.py
â”‚   â”œâ”€â”€ verify_media_type.py
â”‚   â””â”€â”€ verify_opinion.py
â”‚
â”œâ”€â”€ datasets/                    # SemEval 2020 Task 11 data
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ dev/
â”‚   â””â”€â”€ test/
â”‚
â””â”€â”€ propaganda_models/           # Trained model outputs
    â”œâ”€â”€ si_model/
    â””â”€â”€ tc_model/
```

---

## References

### Methodology
- [Media Bias/Fact Check Methodology](https://mediabiasfactcheck.com/methodology/)
- [Freedom House - Freedom in the World](https://freedomhouse.org/report/freedom-world)
- [Reporters Without Borders - Press Freedom Index](https://rsf.org/en/index)

### Propaganda Detection
- [SemEval 2020 Task 11: Detection of Propaganda Techniques](https://propaganda.qcri.org/semeval2020-task11/)
- [DeBERTa: Decoding-enhanced BERT with Disentangled Attention](https://arxiv.org/abs/2006.03654)

---

## License

MIT License
